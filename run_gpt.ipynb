{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18845,"status":"ok","timestamp":1704369410872,"user":{"displayName":"Rae Wong","userId":"06747174139206251151"},"user_tz":480},"id":"cy75saA_KfAt","outputId":"6c38990f-1030-4c39-ad37-cf96e1d62ada"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Collecting datasets\n","  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tiktoken\n","  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting wandb\n","  Downloading wandb-0.16.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n","Collecting pyarrow-hotfix (from datasets)\n","  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n","Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-1.39.1-py2.py3-none-any.whl (254 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Installing collected packages: smmap, setproctitle, sentry-sdk, pyarrow-hotfix, docker-pycreds, dill, tiktoken, multiprocess, gitdb, GitPython, wandb, datasets\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed GitPython-3.1.40 datasets-2.16.1 dill-0.3.7 docker-pycreds-0.4.0 gitdb-4.0.11 multiprocess-0.70.15 pyarrow-hotfix-0.6 sentry-sdk-1.39.1 setproctitle-1.3.3 smmap-5.0.1 tiktoken-0.5.2 wandb-0.16.1\n"]}],"source":["!pip install torch numpy transformers datasets tiktoken wandb tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18306,"status":"ok","timestamp":1704369445302,"user":{"displayName":"Rae Wong","userId":"06747174139206251151"},"user_tz":480},"id":"oEhwPEfR8Bf2","outputId":"9190cd14-38b8-45c3-e939-285c4b8d59b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":217,"status":"ok","timestamp":1704369481878,"user":{"displayName":"Rae Wong","userId":"06747174139206251151"},"user_tz":480},"id":"1Suzdrt38VI1","outputId":"67d2847a-8ab4-4e8c-bfbe-41b3a434e417"},"outputs":[],"source":["# navigate to the directory where folder was uploaded\n","# Eg. %cd drive/MyDrive/TA/nanoGPT-master/\n","\n","%cd <path>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13393,"status":"ok","timestamp":1703833030678,"user":{"displayName":"Rae Wong","userId":"06747174139206251151"},"user_tz":480},"id":"m418hlsaUf5h","outputId":"5d8aaf1c-19f5-43cd-f09a-c3bb1f7ea30a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overriding: init_from = gpt2\n","Overriding: start = What is the answer to life, the universe, and everything?\n","Overriding: num_samples = 3\n","Overriding: max_new_tokens = 100\n","loading weights from pretrained gpt: gpt2\n","forcing vocab_size=50257, block_size=1024, bias=True\n","overriding dropout rate to 0.0\n","number of parameters: 123.65M\n","No meta.pkl found, assuming GPT-2 encodings...\n","What is the answer to life, the universe, and everything?\n","\n","One of the most important questions we need to answer is:\n","\n","What is the answer to life?\n","\n","The answer to life is an individual, a theory, an idea. Someone who can answer that question is the answer to life. A theory who can answer that question is a theory whose identity is the answer to life.\n","\n","The idea is an idea; the theory is actually the idea involved. On the other hand, the universe is just a theory, but it is\n","---------------\n","What is the answer to life, the universe, and everything? Probably not. Try explaining to somebody why life is such a convenient answer to an obvious question. Try asking the question \"Why do we have to feel this way?\" Try saying \"Mmmm, my god, I'm so glad you're here.\" Try saying \"This is all due to me.\" Try saying \"I'm not satisfied with this. I'm not satisfied with that.\" Try thinking that death can't be a good thing, but it can be a great thing. Try asking \"Why\n","---------------\n","What is the answer to life, the universe, and everything?\n","\n","\n","Can's you, I'm just telling you that if there is any question of this I have some knowledge, so let's face it, if you say, \"Oh, I don't know precisely what you're talking about.\" Well, that's because the answer to this question is not always right. There are exceptions. But the exception is that you have to be careful not to be caught up in the world that's around you. This is one of those. There are people who\n","---------------\n"]}],"source":["!python sample.py \\\n","    --init_from=gpt2 \\\n","    --start=\"What is the answer to life, the universe, and everything?\" \\\n","    --num_samples=3 --max_new_tokens=100"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84247,"status":"ok","timestamp":1703833167074,"user":{"displayName":"Rae Wong","userId":"06747174139206251151"},"user_tz":480},"id":"w1MSB6mKXVqZ","outputId":"1b8f7bf9-3c11-4164-af5f-176ca203a7e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overriding: init_from = gpt2-large\n","Overriding: start = What is the answer to life, the universe, and everything?\n","Overriding: num_samples = 3\n","Overriding: max_new_tokens = 100\n","loading weights from pretrained gpt: gpt2-large\n","forcing vocab_size=50257, block_size=1024, bias=True\n","overriding dropout rate to 0.0\n","number of parameters: 772.72M\n","config.json: 100% 666/666 [00:00<00:00, 3.30MB/s]\n","model.safetensors: 100% 3.25G/3.25G [00:35<00:00, 91.0MB/s]\n","generation_config.json: 100% 124/124 [00:00<00:00, 735kB/s]\n","No meta.pkl found, assuming GPT-2 encodings...\n","What is the answer to life, the universe, and everything?\n","\n","One of the most important questions we can ask is: What does it mean to be human?\n","\n","If answers to these questions are ambiguous or contradictory, then the answer is not what we'd like. The answer is always something else.\n","\n","The question is \"What is God?\"\n","\n","The question is: \"What makes you a person?\"\n","\n","The question is: \"What is a person?\"\n","\n","The question is: \"What is a God?\"\n","\n","And\n","---------------\n","What is the answer to life, the universe, and everything? Probably nothing.<|endoftext|>The National Transformed School of Theological Studies (NTSS) is a non-sectarian religious and spiritual school that seeks to provide a theological education and spiritual guidance for all students, regardless of their race, religion or background. Our non-sectarian approach seeks to avoid denominationalism and to bring together people of diverse backgrounds and beliefs, while providing a comprehensive theological, pastoral and spiritual education in a secular setting.\n","\n","The NTSS Mission Statement\n","\n","The mission of\n","---------------\n","What is the answer to life, the universe, and everything?\n","\n","\n","Can a man be compassionate, just, and kind if he is not sure of what he has got?\n","\n","\n","Do we care what happens if one child is born and the second and third children don't go to school, or if they never go to school?\n","\n","\n","We don't know what the future holds, and we don't know what the future holds for us.\n","\n","\n","We are doing all we can to make sure the children go to school. Only by giving them the\n","---------------\n"]}],"source":["!python sample.py \\\n","    --init_from=gpt2-large \\\n","    --start=\"What is the answer to life, the universe, and everything?\" \\\n","    --num_samples=3 --max_new_tokens=100"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":821,"status":"ok","timestamp":1704371078439,"user":{"displayName":"Rae Wong","userId":"06747174139206251151"},"user_tz":480},"id":"NfDcxkCnYNLK","outputId":"c2d69971-c03b-4553-9e20-4b8bcc78fb51"},"outputs":[{"name":"stdout","output_type":"stream","text":["train has 12,255 tokens\n","val has 1,416 tokens\n"]}],"source":["!python data/custom/prepare.py"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303699,"status":"ok","timestamp":1704371393245,"user":{"displayName":"Rae Wong","userId":"06747174139206251151"},"user_tz":480},"id":"h0DXp_8AYhkG","outputId":"31621b39-cc36-4b46-b303-c5cf0a667554"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overriding config with config/finetune_custom.py:\n","import time\n","\n","out_dir = 'out-custom'\n","eval_interval = 5\n","eval_iters = 40\n","wandb_log = False # feel free to turn on\n","wandb_project = 'custom'\n","wandb_run_name = 'ft-' + str(time.time())\n","\n","dataset = 'custom'\n","init_from = 'gpt2-xl' # this is the largest GPT-2 model\n","\n","# only save checkpoints if the validation loss improves\n","always_save_checkpoint = False\n","\n","# the number of examples per iter:\n","# 1 batch_size * 32 grad_accum * 1024 tokens = 32,768 tokens/iter\n","# shakespeare has 301,966 tokens, so 1 epoch ~= 9.2 iters\n","batch_size = 1\n","gradient_accumulation_steps = 32\n","max_iters = 20\n","\n","# finetune at constant LR\n","learning_rate = 3e-5\n","decay_lr = False\n","\n","Overriding: init_from = gpt2-large\n","Overriding: compile = False\n","Overriding: block_size = 256\n","tokens per iteration will be: 8,192\n","Initializing from OpenAI GPT-2 weights: gpt2-large\n","loading weights from pretrained gpt: gpt2-large\n","forcing vocab_size=50257, block_size=1024, bias=True\n","overriding dropout rate to 0.0\n","number of parameters: 772.72M\n","num decayed parameter tensors: 146, with 772,445,440 parameters\n","num non-decayed parameter tensors: 290, with 601,600 parameters\n","using fused AdamW: True\n","step 0: train loss 4.1620, val loss 4.1086\n","iter 0: loss 4.1405, time 10197.60ms, mfu -100.00%\n","iter 1: loss 3.9259, time 4642.90ms, mfu -100.00%\n","iter 2: loss 3.5224, time 5753.92ms, mfu -100.00%\n","iter 3: loss 2.7391, time 5714.19ms, mfu -100.00%\n","iter 4: loss 3.2698, time 5732.81ms, mfu -100.00%\n","step 5: train loss 3.4444, val loss 3.9866\n","saving checkpoint to out-custom\n","iter 5: loss 3.5779, time 70357.01ms, mfu 0.18%\n","iter 6: loss 4.5129, time 7263.27ms, mfu 0.33%\n","iter 7: loss 3.8774, time 5778.21ms, mfu 0.52%\n","iter 8: loss 2.5243, time 6721.67ms, mfu 0.65%\n","iter 9: loss 3.3899, time 6526.89ms, mfu 0.78%\n","step 10: train loss 2.8116, val loss 3.9844\n","saving checkpoint to out-custom\n","iter 10: loss 2.4799, time 56123.84ms, mfu 0.72%\n","iter 11: loss 2.3968, time 5785.16ms, mfu 0.87%\n","iter 12: loss 2.5671, time 5836.14ms, mfu 1.00%\n","iter 13: loss 2.3881, time 6089.06ms, mfu 1.10%\n","iter 14: loss 2.5441, time 5832.67ms, mfu 1.21%\n","step 15: train loss 2.3472, val loss 4.1802\n","iter 15: loss 2.0920, time 10327.31ms, mfu 1.21%\n","iter 16: loss 2.3907, time 5851.84ms, mfu 1.30%\n","iter 17: loss 1.1244, time 5895.45ms, mfu 1.38%\n","iter 18: loss 2.0138, time 5921.14ms, mfu 1.46%\n","iter 19: loss 1.0409, time 5884.87ms, mfu 1.53%\n","step 20: train loss 1.6603, val loss 4.5377\n","iter 20: loss 1.8432, time 10241.35ms, mfu 1.50%\n"]}],"source":["!python train.py config/finetune_custom.py --init_from=gpt2-large --compile=False --block_size=256"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":85219,"status":"ok","timestamp":1704371490205,"user":{"displayName":"Rae Wong","userId":"06747174139206251151"},"user_tz":480},"id":"Jex1QSr4X2sh","outputId":"8a1822f8-c6ca-44d3-bd20-e2d9c6d86e08"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overriding: out_dir = out-custom\n","Overriding: start = What is the answer to life, the universe, and everything?\n","Overriding: num_samples = 3\n","Overriding: max_new_tokens = 100\n","number of parameters: 772.72M\n","No meta.pkl found, assuming GPT-2 encodings...\n","What is the answer to life, the universe, and everything? Have any of you looked into it? Have you been so blind to it that you haven't even noticed the whole chess thing has been going on for tens of thousands of years? Do you think that you can get away with not knowing something so big is going on out there? Do you have any idea what it means to the rest of us to not know what is going on? And I don't mean that in a good way, you know I've talked about this before but when it comes\n","---------------\n","What is the answer to life, the universe, and everything? Probably nothing, unless you're a detective. [Applause] [Music] oh no no no I just need a moment to think about something um uh I had this really crazy dream last night uh where I was this little kid I was this little kid I was this little kid I was this little kid [Music] but then the sun came up I wasn't a kid anymore I was a detective [Music] oh [Applause] [Music] are you okay detective [Music]\n","---------------\n","What is the answer to life, the universe, and everything? I want to be the answer I want to be the answer if there is one thing I never thought I'd say, but the question ain't just for me now, it's for everyone and that's precisely what's so damn refreshing about this time of year yeah the answer to life, the universe, and everything is very clear if you just put your mind to it well if you just put your mind to it well I know this is just a pre-season game but I don't care if\n","---------------\n"]}],"source":["!python sample.py \\\n","    --out_dir=out-custom \\\n","    --start=\"What is the answer to life, the universe, and everything?\" \\\n","    --num_samples=3 --max_new_tokens=100"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.3"},"vscode":{"interpreter":{"hash":"b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"}}},"nbformat":4,"nbformat_minor":0}
